{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/xqcxqc/CSC448/blob/main/448_hw4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "S8PKiVJaL_AW",
    "outputId": "23c2a4cd-0c53-4a1c-c454-7ed87e392a8c"
   },
   "outputs": [],
   "source": [
    "# Imports and pip installations (if needed)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for data set split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "# to use LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to use support vector machine\n",
    "from sklearn import svm\n",
    "\n",
    "#Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Use sklearn to train a k-Neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A05Q5B0_NUX9"
   },
   "source": [
    "# Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "YZ4MUsbXNZ0P",
    "outputId": "77e7a628-792f-4d28-b7b1-e06f4db3efd3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                 5.1               3.5                1.4               0.2   \n",
       "1                 4.9               3.0                1.4               0.2   \n",
       "2                 4.7               3.2                1.3               0.2   \n",
       "3                 4.6               3.1                1.5               0.2   \n",
       "4                 5.0               3.6                1.4               0.2   \n",
       "5                 5.4               3.9                1.7               0.4   \n",
       "6                 4.6               3.4                1.4               0.3   \n",
       "7                 5.0               3.4                1.5               0.2   \n",
       "8                 4.4               2.9                1.4               0.2   \n",
       "9                 4.9               3.1                1.5               0.1   \n",
       "10                5.4               3.7                1.5               0.2   \n",
       "11                4.8               3.4                1.6               0.2   \n",
       "12                4.8               3.0                1.4               0.1   \n",
       "13                4.3               3.0                1.1               0.1   \n",
       "14                5.8               4.0                1.2               0.2   \n",
       "\n",
       "    Types  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       0  \n",
       "10      0  \n",
       "11      0  \n",
       "12      0  \n",
       "13      0  \n",
       "14      0  "
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "iris  = load_iris()\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "\n",
    "#convert the sklearn.utils.bunch to dataframe\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# insert the type column to compelete the data frame\n",
    "types = iris['target']\n",
    "df['Types'] = types\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   Types              150 non-null    int32  \n",
      "dtypes: float64(4), int32(1)\n",
      "memory usage: 5.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "print( df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)       Types  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRMtsJKBaxWu"
   },
   "source": [
    "## About the dataset\n",
    "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?\n",
    "<br>\n",
    "\n",
    "This data set is about the iris flower. For each object in the dataser, it has five attributes which are \"sepal length\", \"sepal width\", \"petal length\", \"petal width\", and \"types\". These length and width values are quantitative(numeric) attributes and indicate the object's length and width. The type value is a categorical attribute and it tells what kind of flower the object is.\n",
    "<br>\n",
    "\n",
    "The features are \"sepal length\", \"sepal width\", \"petal length\", and petal width. The label is the \"type\". We map those features to the label. When the value of type is 0, the class of flower is <b>Setosa</b>. When the value of type is 1, the class of flower is <b>Versicolour</b>. When the value of type is 2, the class of flower is <b>Virginica</b>. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhKaIrZKNaHg"
   },
   "source": [
    "# Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrgogB62NcOi",
    "outputId": "7bbfb1ea-88ed-4944-ab94-48696b9a71df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "# of training set:  135\n",
      "# of test set:  15\n",
      "Lable:\n",
      "# of training set:  135\n",
      "# of test set:  15\n"
     ]
    }
   ],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "\n",
    "features = df[[\"sepal length (cm)\", \"sepal width (cm)\",\"petal length (cm)\", \"petal width (cm)\"]]\n",
    "#print(features.head())\n",
    "\n",
    "label = df[\"Types\"]\n",
    "#print(label.head(140))\n",
    "\n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train,X_test, y_train, y_test = train_test_split(features, label, test_size=0.1)\n",
    "print(\"Features:\")\n",
    "print(\"# of training set: \", X_train.shape[0])\n",
    "print(\"# of test set: \", X_test.shape[0])\n",
    "\n",
    "\n",
    "print(\"Lable:\")\n",
    "print(\"# of training set: \", y_train.shape[0])\n",
    "print(\"# of test set: \", y_test.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hblF-ei9Ncia"
   },
   "source": [
    "# Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhFhEN03Nf7o",
    "outputId": "15a94661-020b-4520-b5f3-c34fdfb042f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986533</td>\n",
       "      <td>0.013467</td>\n",
       "      <td>5.045770e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor     virginica\n",
       "0  0.986533    0.013467  5.045770e-09"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "clf = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "sampledata = np.array( [[6.0, 4.0, 1.2, 0.2]] )\n",
    "\n",
    "probability = pd.DataFrame(clf.predict_proba(sampledata), columns=iris['target_names'])\n",
    "probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on testing set is 0.9333333333333333\n",
      "The score on training set is 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "#iii. Report on the score for Logistic regression model, what does the score measure? <br>\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"The score on testing set is\", score)\n",
    "\n",
    "score = clf.score(X_train, y_train)\n",
    "print(\"The score on training set is\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report:\n",
    "The socre here is the mean accuracy on the testing data and label. The socre on the testing set is 0.93 out of 1. We can say that generlly the results from our model have about 7% of error to reach the exact result. Or we may say that the square of residual sum is 7% of the total sum of squares, which is small. We also can say that the model has 93% of chance to get the correct result. Therefore, we can think this score is good, and our model is able to work at most of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficents are  [[-0.44335822  0.8820754  -2.43760004 -1.03732152]\n",
      " [ 0.3219673  -0.32763052 -0.19819612 -0.8871256 ]\n",
      " [ 0.12139093 -0.55444488  2.63579616  1.92444712]]\n",
      "The intercepts are  [ 10.05946055   3.29507865 -13.3545392 ]\n"
     ]
    }
   ],
   "source": [
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "\n",
    "print(\"The coefficents are \",clf.coef_)\n",
    "print(\"The intercepts are \",clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDUpXQN4Nilk"
   },
   "source": [
    "# Part 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U__zukpdNqiQ",
    "outputId": "5cd81a50-9137-4f36-842e-0687e9bc7c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "\n",
    "    # Support vector machines (SVMs) are a set of supervised learning methods used for \n",
    "    # classification, regression and outliers detection.\n",
    "\n",
    "svm_clf = svm.SVC(probability = True, random_state = np.random.seed())\n",
    "    # probabilitybool, default=False\n",
    "    # Whether to enable probability estimates. This must be enabled prior to calling fit, \n",
    "    # will slow down that method as it internally uses 5-fold cross-validation, \n",
    "    # and predict_proba may be inconsistent with predict.\n",
    "svm_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.015288</td>\n",
       "      <td>0.010773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica\n",
       "0  0.973939    0.015288   0.010773"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "\n",
    "sampledata = np.array( [[6.0, 4.0, 1.2, 0.2]] )\n",
    "\n",
    "probability = pd.DataFrame(svm_clf.predict_proba(sampledata), columns=iris['target_names'])\n",
    "probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on testing set is 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "svm_score = svm_clf.score(X_test, y_test)\n",
    "print(\"The score on testing set is\", svm_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report:\n",
    " The socre on the testing set is 0.93 out of 1. We can say that generlly the results from our model have about 7% of error to reach the exact result, which is small. We also can say that the model has 93% of chance to get the correct result. Therefore, we can think this score is good, and our model is able to work at most of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULoL7mMBNrlS"
   },
   "source": [
    "# Part 5: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKKmODVrN9lQ",
    "outputId": "dced24f7-c6bd-45fb-c68f-87548e9228dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(5, 4), max_iter=1000,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "nn_clf = MLPClassifier(solver='lbfgs',max_iter=1000,\n",
    "                       hidden_layer_sizes=(5,4), activation=\"logistic\", random_state=np.random.seed())\n",
    "\n",
    "nn_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.312810e-08</td>\n",
       "      <td>6.696909e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   setosa    versicolor     virginica\n",
       "0     1.0  5.312810e-08  6.696909e-15"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "sampledata = np.array( [[6.0, 4.0, 1.2, 0.2]] )\n",
    "\n",
    "probability = pd.DataFrame(nn_clf.predict_proba(sampledata), columns=iris['target_names'])\n",
    "probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on testing set is 1.0\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "nn_score = nn_clf.score(X_test, y_test)\n",
    "print(\"The score on testing set is\", nn_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report:\n",
    "The socre here is the mean accuracy on the testing data and label. The socre on the testing set is 1 out of 1. We can say that the results from our model have no error, or the model has 100% of chance to get the correct result. Therefore, we can think this score is perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using stochastic gradient descent solver, the score on testing set is 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# iv: Experiment with different options for the neural network, \n",
    "#report on your best configuration \n",
    "#(the highest score I was able to achieve was 0.8666)\n",
    "\n",
    "sgd = MLPClassifier(solver='sgd',max_iter=3000,\n",
    "                       hidden_layer_sizes=(7), activation=\"logistic\", random_state=np.random.seed())\n",
    "\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "sgd_score = sgd.score(X_test, y_test)\n",
    "\n",
    "print(\"Using stochastic gradient descent solver, the score on testing set is\", sgd_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using adam solver, the score on testing set is 1.0\n"
     ]
    }
   ],
   "source": [
    "adam = MLPClassifier(solver='adam',max_iter=3000,\n",
    "                       hidden_layer_sizes=(4), activation=\"logistic\", random_state=np.random.seed())\n",
    "\n",
    "adam.fit(X_train, y_train)\n",
    "\n",
    "adam_score = adam.score(X_test, y_test)\n",
    "\n",
    "print(\"Using adam solver, the score on testing set is\", adam_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report:\n",
    "<br>\n",
    "To experiment with different options for the neural network, I use all 3 types of slover.<br><br>\n",
    "For \"lbfgs\" slover, the configuration I use is (5,4) for the hidden layer size. And the activation fucntion is logistic function(sigmoid funciton). The score on the testing set is 1, which is the perfect socre and the best score I got. However, there is small chance to get other scores like 0.866 and 0933, when we run the code many times. \n",
    "<br><br>\n",
    "The second solver is \"sgd\". the configuration I use is (7) for the hidden layer size. And the activation fucntion is logistic function. The score on the testing set is 0.866, which is the best score I got for this configuration. However, there is small chance to get other scores like 0.533 and 0933, when we run the code many times. \n",
    "<br><br>\n",
    "The last solver is \"adam\". In this time, the configuration I use is (4) for the hidden layer size. And the activation fucntion is logistic function. The score on the testing set is 1, which is the best score I got for this configuration. This configuration is more stable than the other two, because the socre is the same while I run the code many times. \n",
    "<br>\n",
    "I think the best configuration I have is the one using \"adam\" solver. Because the socre is the perfect score, and I think this configuraion is the most stable one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bi5tDwHmC28"
   },
   "source": [
    "# Part 6: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCFlfJy2mCg6",
    "outputId": "e71bf88c-6418-4b7f-e289-4acf743c16cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=28)"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=28)\n",
    "knn_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   setosa  versicolor  virginica\n",
       "0     1.0         0.0        0.0"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "sampledata = np.array( [[6.0, 4.0, 1.2, 0.2]] )\n",
    "\n",
    "probability = pd.DataFrame(knn_clf.predict_proba(sampledata), columns=iris['target_names'])\n",
    "probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on testing set is 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "knn_score = knn_clf.score(X_test, y_test)\n",
    "print(\"The score on testing set is\", knn_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report:\n",
    " The socre on the testing set is 0.93 out of 1. We can say that generlly the results from our model have about 7% of error to reach the exact result, which is small. We also can say that the model has 93% of chance to get the correct result. Therefore, we can think this score is good, and our model is able to work at most of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "162Sw3LeoqE2"
   },
   "source": [
    "# Part 7: Conclusions and takeaways\n",
    "\n",
    "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report:\n",
    "<br>\n",
    "In general, the results of these models are all good. Most of them have scores higher than 90%, which means that these models are able to predict correctly in the most of times. \n",
    "<br> <br> \n",
    "One thing surprises me is that for K-Nearest Neighbors model, the score decreases when the neighbors is larger. According to my test, this model's socre is 0.933 when the number of neighbors is from 1 to 28. After that, the socre decrease when the number of neighbors reach a bigger enough number. This suprises me because I learn that it might not be good if k is large. And it could be hard to use, since we need to choose the best k for different dataset.\n",
    "<br> <br> \n",
    "The other thing surprise me is the Neural Network model. The socres I got from the same configuration could be different sometimes when I used lbfgs and sgd as my solver. And one more thing surprise me is adam solver. Compare to lbfgs and sgd, adam solver gives me the perfect score even it works well on large dataset(our dataset is small). And according to my experiments, the score I got from using adam solver is stable. \n",
    "<br><br>\n",
    "Some of these model are really good such as Logistic Regression. Because it can give us high socre, and it is easy to implement.  However, I think Neural network with adam solver is the model performed the best on the dataset .\n",
    "Because Neural network can give us the perfect score, which is the highest score here. One bad thing is that it take more iterations to converge, which make it slower than other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
