{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/xqcxqc/CSC448/blob/main/448_hw3.ipynb" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 15 rows of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature 째C</th>\n",
       "      <th>Mols KCL</th>\n",
       "      <th>Size nm^3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469</td>\n",
       "      <td>647</td>\n",
       "      <td>6.244743e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>403</td>\n",
       "      <td>694</td>\n",
       "      <td>5.779610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>975</td>\n",
       "      <td>6.196847e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779</td>\n",
       "      <td>916</td>\n",
       "      <td>1.460449e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>901</td>\n",
       "      <td>18</td>\n",
       "      <td>4.325726e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>545</td>\n",
       "      <td>637</td>\n",
       "      <td>7.124634e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>660</td>\n",
       "      <td>519</td>\n",
       "      <td>7.006960e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>143</td>\n",
       "      <td>869</td>\n",
       "      <td>2.718260e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89</td>\n",
       "      <td>461</td>\n",
       "      <td>8.919803e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>294</td>\n",
       "      <td>776</td>\n",
       "      <td>4.770210e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>991</td>\n",
       "      <td>117</td>\n",
       "      <td>2.441771e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>307</td>\n",
       "      <td>781</td>\n",
       "      <td>5.006455e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>206</td>\n",
       "      <td>70</td>\n",
       "      <td>3.145200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>437</td>\n",
       "      <td>599</td>\n",
       "      <td>5.390215e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>566</td>\n",
       "      <td>75</td>\n",
       "      <td>9.185271e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temperature 째C  Mols KCL     Size nm^3\n",
       "0              469       647  6.244743e+05\n",
       "1              403       694  5.779610e+05\n",
       "2              302       975  6.196847e+05\n",
       "3              779       916  1.460449e+06\n",
       "4              901        18  4.325726e+04\n",
       "5              545       637  7.124634e+05\n",
       "6              660       519  7.006960e+05\n",
       "7              143       869  2.718260e+05\n",
       "8               89       461  8.919803e+04\n",
       "9              294       776  4.770210e+05\n",
       "10             991       117  2.441771e+05\n",
       "11             307       781  5.006455e+05\n",
       "12             206        70  3.145200e+04\n",
       "13             437       599  5.390215e+05\n",
       "14             566        75  9.185271e+04"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pandas load the dataset (load remotely, not locally)\n",
    "newlife = pd.read_csv(\"https://raw.githubusercontent.com/profmcnich/example_notebook/main/science_data_large.csv\")\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "print(\"The first 15 rows of the data:\")\n",
    "newlife.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the table information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Temperature 째C  1000 non-null   int64  \n",
      " 1   Mols KCL        1000 non-null   int64  \n",
      " 2   Size nm^3       1000 non-null   float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 23.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "print(\"Summary of the table information:\")\n",
    "newlife.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "# of training set:  900\n",
      "# of test set:  100\n",
      "Lable:\n",
      "# of training set:  900\n",
      "# of test set:  100\n"
     ]
    }
   ],
   "source": [
    "# Take the pandas dataset and split it into our features (X) and label (y)\n",
    "\n",
    "#temp and kcl are the x, size is the y\n",
    "features = newlife[[\"Temperature 째C\", \"Mols KCL\"]]\n",
    "#print(features.head())\n",
    "\n",
    "label = newlife[\"Size nm^3\"]\n",
    "#print(label.head())\n",
    "\n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train,X_test, y_train, y_test = train_test_split(features, label, test_size=0.1)\n",
    "print(\"Features:\")\n",
    "print(\"# of training set: \", X_train.shape[0])\n",
    "print(\"# of test set: \", X_test.shape[0])\n",
    "\n",
    "\n",
    "print(\"Lable:\")\n",
    "print(\"# of training set: \", y_train.shape[0])\n",
    "print(\"# of test set: \", y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Perform a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted output of the sample data is 682812.4505806162\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to train a model on the training set\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Create a sample datapoint and predict the output of that sample with the trained model\n",
    "sampledata = np.array([[479,657]])\n",
    "sample_output = reg.predict(sampledata)\n",
    "print(\"The predicted output of the sample data is\",sample_output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trainning score is  0.862698175289108\n",
      "The testing score on model is  0.8372727559091409\n"
     ]
    }
   ],
   "source": [
    "# Report on the score for that model, in your own words (markdown, not code) \n",
    "#explain what the score means\n",
    "\n",
    "print(\"The trainning score is \",reg.score(X_train, y_train))\n",
    "print(\"The testing score on model is \",reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report:\n",
    "The score is the coefficient of determination of the prediction. The coefficient of determination  is defined as $(1 - u/v)$, where $u$ is the residual sum of squares and $v$ is the total sum of squares. The smaller $u$, the higher accurcy of the model. The score of model on the test set is about 0.84. This means $u/v = 0.16$. The residual sum of squares is 16% of the total sum of squares. Thus, we can say that the residual sum of squares is small but not small enough. So the score shows that the model works but the error is not small enough. Also, the score on train set is 0.86 and the score on the test set is about 0.84. They are close, so we can say the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficents are  [ 883.76625  1039.641116]\n",
      "The intercept is  -423555.796795\n"
     ]
    }
   ],
   "source": [
    "# Extract the coefficents and intercept from the model and write an equation \n",
    "#for your h(x) using LaTeX\n",
    "\n",
    "lin_coefficents = np.round_(reg.coef_, decimals=6)\n",
    "lin_intercept = round(reg.intercept_, 6)\n",
    "print(\"The coefficents are \",lin_coefficents)\n",
    "print(\"The intercept is \",lin_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h(x) = -423555.796795 + 883.76625x_1 + 1039.641116x_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Use Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores are  [0.88386739 0.87208105 0.85297462 0.85406898 0.84251888 0.84657007\n",
      " 0.86888904 0.84855293 0.86782045 0.83085248 0.79184984 0.84158423\n",
      " 0.85345798 0.86806507 0.88476173 0.88165459 0.80460948 0.86239754\n",
      " 0.85827757 0.8588158  0.86487048 0.87121011 0.87102872 0.87466958\n",
      " 0.86130699 0.86099564 0.83895886 0.87309954 0.85039092 0.8789083\n",
      " 0.86349871 0.85488994 0.8635317  0.88266857 0.86314608 0.85661997\n",
      " 0.8593868  0.83038982 0.87637776 0.85542685 0.83742336 0.86186512\n",
      " 0.84699481 0.83549662 0.86995281 0.85365513 0.88167333 0.84986393\n",
      " 0.87706843 0.87988079 0.86318567 0.82727232 0.83219476 0.83070757\n",
      " 0.83806331 0.86875569 0.88680216 0.85631775 0.87531773 0.82460615\n",
      " 0.8808887  0.87156092 0.86002464 0.81606204 0.80363943 0.76462415\n",
      " 0.87795794 0.90138612 0.844838   0.8644437  0.8528658  0.87276007\n",
      " 0.8593277  0.84750053 0.8562711  0.86846288 0.8397737  0.87744955\n",
      " 0.8472922  0.84597692 0.88055486 0.81403015 0.86404553 0.8419025\n",
      " 0.84814963 0.85478396 0.85937197 0.86082013 0.7966563  0.84437741\n",
      " 0.84463496 0.87496489 0.86855443 0.84285489 0.85809279 0.85435835\n",
      " 0.85636522 0.87523661 0.85428356 0.88449931]\n",
      "0.856 accuracy with a standard deviation of 0.022\n"
     ]
    }
   ],
   "source": [
    "# Use the cross_val_score function to repeat your experiment across many\n",
    "#shuffles of the data\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.1, random_state=10)\n",
    "scores = cross_val_score(reg, features, label, cv=cv)\n",
    "print(\"The scores are \",scores)\n",
    "\n",
    "print(\"%0.3f accuracy with a standard deviation of %0.3f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "# Report on their finding and their significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report:\n",
    "\n",
    "To improve the validation of a model, we can use validation set by further patitioning the data. However, using a validation set will reduce the number of samples whcih can be used for learning the model, which will make the model weak. Thus, we use cross validation. In cross validation, we will have a training set and test set, but we don't need to make a validation set. Instead, we spit the trainning set into $k$ smaller sets, and from each samll set, we save 1 fold for later test. In this way, we are able to waste less data.\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. According to the code and output above, we use a 100-folds cross validation, and the average of the scores is 0.856 with a standard deviation of 0.022. This means that the socre for this model is validated. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Using Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing score is  1.0\n",
      "The trainning score is  1.0\n"
     ]
    }
   ],
   "source": [
    "# Using the PolynomialFeatures library perform another regression on an \n",
    "#augmented dataset of degree 2\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# fit to an order-2 polynomial data\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "#now the features of training set have been transformed from [x1,x2] to [1,x1,x2...]\n",
    "# and can be used within any linear model\n",
    "\n",
    "#poly model:\n",
    "poly_model = LinearRegression().fit(X_train_poly, y_train)\n",
    "train_score = poly_model.score(X_train_poly, y_train)\n",
    "test_score = poly_model.score(X_test_poly, y_test)\n",
    "\n",
    "print(\"The testing score is \",test_score)\n",
    "print(\"The trainning score is \",train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficents are [ 0.       12.       -0.       -0.        2.        0.028571]\n",
      "The intercpet  is 1.7e-05\n"
     ]
    }
   ],
   "source": [
    "# Report on the metrics and output the resultant equation as you did in Part 3.\n",
    "pol_coefficents = np.round_(poly_model.coef_, decimals=6)\n",
    "pol_intercept = round(poly_model.intercept_, 6)\n",
    "\n",
    "print(f\"The coefficents are\",pol_coefficents)\n",
    "print(f\"The intercpet  is\",pol_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h(x)=12x_1 + 2x_1x_2 + 0.028571x_2^2 + 0.000017$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "By using \"fit_transform\" method from a library, PolynomialFeatures, we transform the trainning set and test set into a 2-degree matrix. And then the sets can be used within any linear model. By using new training set on the linear regression, we have a polynomial regression model. The socre of this model on test set is 1, which is a perfect socre. This means the model works perdectly without any error. The socre of this model on training set also is 1, which is the same with the socre on test set. This means our model works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
